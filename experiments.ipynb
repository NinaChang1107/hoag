{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Might want to install library \"tabulate\" for a better dictionary printing\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "seaborn.set_style('white')\n",
    "import hoag \n",
    "import mod_l_exp.utils as mlx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets.redivide_data:, computed partitions numbers - [0, 30000, 60000, 90000] len all 90000 DONE\n"
     ]
    }
   ],
   "source": [
    "dataset = mlx.generate_multiclass_dataset(n_samples=90000, n_features=1000, n_informative=50, n_redundant=25, n_repeated=0,\n",
    "                                      n_classes=2, n_clusters_per_class=3,\n",
    "                                      flip_y=0.1, class_sep=1.0,\n",
    "                                      random_state=1, hot_encoded=False, partitions_proportions=[1/3, 1/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESPONSE  FUNCTION for $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting: we use logistic regression (for binary classification) and optimize regularization hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "alphas = np.linspace(-0, 20, 50)\n",
    "\n",
    "def cost_func(a):\n",
    "    clf = linear_model.LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        C=np.exp(-a), fit_intercept=True, \n",
    "        tol=1e-15, max_iter=500)\n",
    "\n",
    "    clf.fit(dataset.train.data, dataset.train.target)\n",
    "    cost = linear_model.logistic._logistic_loss(clf.coef_.ravel(), \n",
    "                                                dataset.validation.data, dataset.validation.target, 0.)\n",
    "    print('.', end='')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMAY3pIkBcbwliQpMHdCQ2qLTpy9MQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e2154a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = [cost_func(a) for a in alphas]\n",
    "plt.plot(alphas, scores)\n",
    "plt.title('minumum at ' + str(alphas[np.argmin(scores)]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the optimal $\\alpha$ is outside of default interval..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOAG - NO BOUNDS ON $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started hoag\n",
      "\n",
      "Log step 0\n",
      "training error [ 1215426.07830054]\n",
      "validation error 1214580.71371\n",
      "test error 1222810.27415\n",
      "validation accuracy 0.5034\n",
      "test accuracy 0.5021\n",
      "alpha [ 20.]\n",
      "der alpha [ 0.]\n",
      "step size 0.0\n",
      "inner level iterations: 1, inner objective 20852.2951225, grad norm 263094.59684742737\n",
      "Inverting matrix with precision 0.001\n",
      "increased step size\n",
      "it 1, g: 20771.6672043, incr: -inf, sum lambda 19.0, epsilon: 0.0009000000000000001, L: 20.7384742337, norm grad_lambda: 21.8299728775\n",
      "\n",
      "Log step 1\n",
      "training error [ 20771.66695779]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 20.]\n",
      "der alpha 21.8299728775\n",
      "step size 0.0458085772992\n",
      "inner level iterations: 0, inner objective 20801.3283999, grad norm 122623.6517591924\n",
      "Inverting matrix with precision 0.0009000000000000001\n",
      "it 2, g: 20771.6672043, incr: 0.0, sum lambda 17.9573988528, epsilon: 0.0008100000000000001, L: 20.7384742337, norm grad_lambda: 21.6219570281\n",
      "\n",
      "Log step 2\n",
      "training error [ 20771.66695762]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 19.]\n",
      "der alpha 21.6219570281\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20782.1236963, grad norm 104107.45939680193\n",
      "Inverting matrix with precision 0.0008100000000000001\n",
      "it 3, g: 20771.6672043, incr: 0.0, sum lambda 16.9426156962, epsilon: 0.000729, L: 20.7384742337, norm grad_lambda: 21.0450543455\n",
      "\n",
      "Log step 3\n",
      "training error [ 20771.66695745]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 17.95739885]\n",
      "der alpha 21.0450543455\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20775.4573249, grad norm 107035.71703349726\n",
      "Inverting matrix with precision 0.000729\n",
      "it 4, g: 20771.6672043, incr: 0.0, sum lambda 15.9952397563, epsilon: 0.0006561000000000001, L: 20.7384742337, norm grad_lambda: 19.6471315195\n",
      "\n",
      "Log step 4\n",
      "training error [ 20771.66695728]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 16.9426157]\n",
      "der alpha 19.6471315195\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20773.1366979, grad norm 109191.86031765818\n",
      "Inverting matrix with precision 0.0006561000000000001\n",
      "it 5, g: 20771.6672043, incr: 0.0, sum lambda 15.1749129443, epsilon: 0.00059049, L: 20.7384742337, norm grad_lambda: 17.0123264533\n",
      "\n",
      "Log step 5\n",
      "training error [ 20771.66695712]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 15.99523976]\n",
      "der alpha 17.0123264533\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20772.3140645, grad norm 110087.46191295795\n",
      "Inverting matrix with precision 0.00059049\n",
      "it 6, g: 20771.6672043, incr: 0.0, sum lambda 14.5203164539, epsilon: 0.000531441, L: 20.7384742337, norm grad_lambda: 13.5753324493\n",
      "\n",
      "Log step 6\n",
      "training error [ 20771.66695699]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 15.17491294]\n",
      "der alpha 13.5753324493\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20772.0032263, grad norm 110443.17838145845\n",
      "Inverting matrix with precision 0.000531441\n",
      "it 7, g: 20771.6672043, incr: 0.0, sum lambda 14.0143489784, epsilon: 0.0004782969, L: 20.7384742337, norm grad_lambda: 10.4929934527\n",
      "\n",
      "Log step 7\n",
      "training error [ 20771.66695688]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 14.52031645]\n",
      "der alpha 10.4929934527\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.8697001, grad norm 110598.85973151424\n",
      "Inverting matrix with precision 0.0004782969\n",
      "it 8, g: 20771.6672043, incr: 0.0, sum lambda 13.6185516586, epsilon: 0.00043046721, L: 20.7384742337, norm grad_lambda: 8.20823252031\n",
      "\n",
      "Log step 8\n",
      "training error [ 20771.66695679]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 14.01434898]\n",
      "der alpha 8.20823252031\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.8034313, grad norm 110676.76268043755\n",
      "Inverting matrix with precision 0.00043046721\n",
      "it 9, g: 20771.6672043, incr: 0.0, sum lambda 13.2998514344, epsilon: 0.000387420489, L: 20.7384742337, norm grad_lambda: 6.60935638603\n",
      "\n",
      "Log step 9\n",
      "training error [ 20771.66695673]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 13.61855166]\n",
      "der alpha 6.60935638603\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.7661859, grad norm 110720.73236639844\n",
      "Inverting matrix with precision 0.000387420489\n",
      "it 10, g: 20771.6672043, incr: 0.0, sum lambda 13.0361767697, epsilon: 0.0003486784401, L: 20.7384742337, norm grad_lambda: 5.4682102399\n",
      "\n",
      "Log step 10\n",
      "training error [ 20771.66695667]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 13.29985143]\n",
      "der alpha 5.4682102399\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.7431864, grad norm 110747.95077107781\n",
      "Inverting matrix with precision 0.0003486784401\n",
      "it 11, g: 20771.6672043, incr: 0.0, sum lambda 12.8128095626, epsilon: 0.00031381059609000004, L: 20.7384742337, norm grad_lambda: 4.63229506972\n",
      "\n",
      "Log step 11\n",
      "training error [ 20771.66695663]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 13.03617677]\n",
      "der alpha 4.63229506972\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.7279264, grad norm 110766.0380170604\n",
      "Inverting matrix with precision 0.00031381059609000004\n",
      "it 12, g: 20771.6672043, incr: 0.0, sum lambda 12.6198753346, epsilon: 0.00028242953648100003, L: 20.7384742337, norm grad_lambda: 4.00116151684\n",
      "\n",
      "Log step 12\n",
      "training error [ 20771.66695659]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 12.81280956]\n",
      "der alpha 4.00116151684\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.717228, grad norm 110778.73178649838\n",
      "Inverting matrix with precision 0.00028242953648100003\n",
      "it 13, g: 20771.6672043, incr: 0.0, sum lambda 12.4505865573, epsilon: 0.00025418658283290005, L: 20.7384742337, norm grad_lambda: 3.51079094655\n",
      "\n",
      "Log step 13\n",
      "training error [ 20771.66695656]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 12.61987533]\n",
      "der alpha 3.51079094655\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.7093986, grad norm 110788.02838314523\n",
      "Inverting matrix with precision 0.00025418658283290005\n",
      "it 14, g: 20771.6672043, incr: 0.0, sum lambda 12.3000995106, epsilon: 0.00022876792454961005, L: 20.7384742337, norm grad_lambda: 3.12087173976\n",
      "\n",
      "Log step 14\n",
      "training error [ 20771.66695653]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 12.45058656]\n",
      "der alpha 3.12087173976\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.7034687, grad norm 110795.07351261488\n",
      "Inverting matrix with precision 0.00022876792454961005\n",
      "it 15, g: 20771.6672043, incr: 0.0, sum lambda 12.1648785697, epsilon: 0.00020589113209464906, L: 20.7384742337, norm grad_lambda: 2.80427599969\n",
      "\n",
      "Log step 15\n",
      "training error [ 20771.66695651]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 12.30009951]\n",
      "der alpha 2.80427599969\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6988505, grad norm 110800.56258572314\n",
      "Inverting matrix with precision 0.00020589113209464906\n",
      "it 16, g: 20771.6672043, incr: 0.0, sum lambda 12.0422594406, epsilon: 0.00018530201888518417, L: 20.7384742337, norm grad_lambda: 2.54293364745\n",
      "\n",
      "Log step 16\n",
      "training error [ 20771.66695649]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 12.16487857]\n",
      "der alpha 2.54293364745\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6951697, grad norm 110804.93892081814\n",
      "Inverting matrix with precision 0.00018530201888518417\n",
      "it 17, g: 20771.6672043, incr: 0.0, sum lambda 11.9302291771, epsilon: 0.00016677181699666576, L: 20.7384742337, norm grad_lambda: 2.3233367347\n",
      "\n",
      "Log step 17\n",
      "training error [ 20771.66695646]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 12.04225944]\n",
      "der alpha 2.3233367347\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6921794, grad norm 110808.49528351211\n",
      "Inverting matrix with precision 0.00016677181699666576\n",
      "it 18, g: 20771.6672043, incr: 0.0, sum lambda 11.8271949091, epsilon: 0.0001500946352969992, L: 20.7384742337, norm grad_lambda: 2.13677351059\n",
      "\n",
      "Log step 18\n",
      "training error [ 20771.66695645]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.93022918]\n",
      "der alpha 2.13677351059\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6897098, grad norm 110811.43301595218\n",
      "Inverting matrix with precision 0.0001500946352969992\n",
      "it 19, g: 20771.6672043, incr: 0.0, sum lambda 11.7318912274, epsilon: 0.0001350851717672993, L: 20.7384742337, norm grad_lambda: 1.97645294779\n",
      "\n",
      "Log step 19\n",
      "training error [ 20771.66695643]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.82719491]\n",
      "der alpha 1.97645294779\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6876412, grad norm 110813.89408235044\n",
      "Inverting matrix with precision 0.0001350851717672993\n",
      "it 20, g: 20771.6672043, incr: 0.0, sum lambda 11.6433007753, epsilon: 0.00012157665459056936, L: 20.7384742337, norm grad_lambda: 1.83723080866\n",
      "\n",
      "Log step 20\n",
      "training error [ 20771.66695641]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.73189123]\n",
      "der alpha 1.83723080866\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6858874, grad norm 110815.98103682982\n",
      "Inverting matrix with precision 0.00012157665459056936\n",
      "it 21, g: 20771.6672043, incr: 0.0, sum lambda 11.5605847304, epsilon: 0.00010941898913151243, L: 20.7384742337, norm grad_lambda: 1.71540456561\n",
      "\n",
      "Log step 21\n",
      "training error [ 20771.6669564]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.64330078]\n",
      "der alpha 1.71540456561\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6843844, grad norm 110817.76981226646\n",
      "Inverting matrix with precision 0.00010941898913151243\n",
      "it 22, g: 20771.6672043, incr: 0.0, sum lambda 11.4830521943, epsilon: 9.847709021836118e-05, L: 20.7384742337, norm grad_lambda: 1.60790650165\n",
      "\n",
      "Log step 22\n",
      "training error [ 20771.66695638]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.56058473]\n",
      "der alpha 1.60790650165\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6830841, grad norm 110819.31751123453\n",
      "Inverting matrix with precision 9.847709021836118e-05\n",
      "it 23, g: 20771.6672043, incr: 0.0, sum lambda 11.4101223726, epsilon: 8.862938119652506e-05, L: 20.7384742337, norm grad_lambda: 1.51245322958\n",
      "\n",
      "Log step 23\n",
      "training error [ 20771.66695637]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.48305219]\n",
      "der alpha 1.51245322958\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6819496, grad norm 110820.66791983932\n",
      "Inverting matrix with precision 8.862938119652506e-05\n",
      "it 24, g: 20771.6672043, incr: 0.0, sum lambda 11.3413093233, epsilon: 7.976644307687256e-05, L: 20.7384742337, norm grad_lambda: 1.42707764898\n",
      "\n",
      "Log step 24\n",
      "training error [ 20771.66695636]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.41012237]\n",
      "der alpha 1.42707764898\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6809524, grad norm 110821.85499568863\n",
      "Inverting matrix with precision 7.976644307687256e-05\n",
      "it 25, g: 20771.6672043, incr: 0.0, sum lambda 11.2761963889, epsilon: 7.17897987691853e-05, L: 20.7384742337, norm grad_lambda: 1.35034291333\n",
      "\n",
      "Log step 25\n",
      "training error [ 20771.66695635]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.34130932]\n",
      "der alpha 1.35034291333\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.68007, grad norm 110822.9055467255\n",
      "Inverting matrix with precision 7.17897987691853e-05\n",
      "it 26, g: 20771.6672043, incr: 0.0, sum lambda 11.2144259412, epsilon: 6.461081889226677e-05, L: 20.7384742337, norm grad_lambda: 1.28102483677\n",
      "\n",
      "Log step 26\n",
      "training error [ 20771.66695634]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.27619639]\n",
      "der alpha 1.28102483677\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6792844, grad norm 110823.84095182225\n",
      "Inverting matrix with precision 6.461081889226677e-05\n",
      "it 27, g: 20771.6672043, incr: 0.0, sum lambda 11.1556887522, epsilon: 5.81497370030401e-05, L: 20.7384742337, norm grad_lambda: 1.21811968095\n",
      "\n",
      "Log step 27\n",
      "training error [ 20771.66695633]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.21442594]\n",
      "der alpha 1.21811968095\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.678581, grad norm 110824.67844955952\n",
      "Inverting matrix with precision 5.81497370030401e-05\n",
      "it 28, g: 20771.6672043, incr: 0.0, sum lambda 11.0997158704, epsilon: 5.233476330273609e-05, L: 20.7384742337, norm grad_lambda: 1.16079216629\n",
      "\n",
      "Log step 28\n",
      "training error [ 20771.66695632]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.15568875]\n",
      "der alpha 1.16079216629\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6779481, grad norm 110825.43207713748\n",
      "Inverting matrix with precision 5.233476330273609e-05\n",
      "it 29, g: 20771.6672043, incr: 0.0, sum lambda 11.0462716924, epsilon: 4.7101286972462485e-05, L: 20.7384742337, norm grad_lambda: 1.10835070875\n",
      "\n",
      "Log step 29\n",
      "training error [ 20771.66695631]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.09971587]\n",
      "der alpha 1.10835070875\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.677376, grad norm 110826.11337330898\n",
      "Inverting matrix with precision 4.7101286972462485e-05\n",
      "it 30, g: 20771.6672043, incr: 0.0, sum lambda 10.9951486214, epsilon: 4.239115827521624e-05, L: 20.7384742337, norm grad_lambda: 1.06021449191\n",
      "\n",
      "Log step 30\n",
      "training error [ 20771.6669563]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 11.04627169]\n",
      "der alpha 1.06021449191\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6768566, grad norm 110826.73190316315\n",
      "Inverting matrix with precision 4.239115827521624e-05\n",
      "it 31, g: 20771.6672043, incr: 0.0, sum lambda 10.9461638313, epsilon: 3.8152042447694614e-05, L: 20.7384742337, norm grad_lambda: 1.01586980612\n",
      "\n",
      "Log step 31\n",
      "training error [ 20771.66695629]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.99514862]\n",
      "der alpha 1.01586980612\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6763832, grad norm 110827.29564504833\n",
      "Inverting matrix with precision 3.8152042447694614e-05\n",
      "it 32, g: 20771.6672043, incr: 0.0, sum lambda 10.8991536924, epsilon: 3.433683820292515e-05, L: 20.7384742337, norm grad_lambda: 0.974918555327\n",
      "\n",
      "Log step 32\n",
      "training error [ 20771.66695628]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.94616383]\n",
      "der alpha 0.974918555327\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6759503, grad norm 110827.81132227638\n",
      "Inverting matrix with precision 3.433683820292515e-05\n",
      "it 33, g: 20771.6672043, incr: 0.0, sum lambda 10.8539732182, epsilon: 3.090315438263264e-05, L: 20.7384742337, norm grad_lambda: 0.936974098834\n",
      "\n",
      "Log step 33\n",
      "training error [ 20771.66695627]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.89915369]\n",
      "der alpha 0.936974098834\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6755529, grad norm 110828.28461487849\n",
      "Inverting matrix with precision 3.090315438263264e-05\n",
      "it 34, g: 20771.6672043, incr: 0.0, sum lambda 10.8104919996, epsilon: 2.7812838944369376e-05, L: 20.7384742337, norm grad_lambda: 0.901734132279\n",
      "\n",
      "Log step 34\n",
      "training error [ 20771.66695627]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.85397322]\n",
      "der alpha 0.901734132279\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.675187, grad norm 110828.72036608745\n",
      "Inverting matrix with precision 2.7812838944369376e-05\n",
      "it 35, g: 20771.6672043, incr: 0.0, sum lambda 10.7685923812, epsilon: 2.503155504993244e-05, L: 20.7384742337, norm grad_lambda: 0.868934157104\n",
      "\n",
      "Log step 35\n",
      "training error [ 20771.66695626]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.810492]\n",
      "der alpha 0.868934157104\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6748492, grad norm 110829.12272774911\n",
      "Inverting matrix with precision 2.503155504993244e-05\n",
      "it 36, g: 20771.6672043, incr: 0.0, sum lambda 10.7281690844, epsilon: 2.2528399544939195e-05, L: 20.7384742337, norm grad_lambda: 0.838317498281\n",
      "\n",
      "Log step 36\n",
      "training error [ 20771.66695625]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.76859238]\n",
      "der alpha 0.838317498281\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6745364, grad norm 110829.49526630173\n",
      "Inverting matrix with precision 2.2528399544939195e-05\n",
      "it 37, g: 20771.6672043, incr: 0.0, sum lambda 10.689126145, epsilon: 2.0275559590445276e-05, L: 20.7384742337, norm grad_lambda: 0.809690993812\n",
      "\n",
      "Log step 37\n",
      "training error [ 20771.66695625]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.72816908]\n",
      "der alpha 0.809690993812\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6742461, grad norm 110829.84107401228\n",
      "Inverting matrix with precision 2.0275559590445276e-05\n",
      "it 38, g: 20771.6672043, incr: 0.0, sum lambda 10.6513767926, epsilon: 1.8248003631400748e-05, L: 20.7384742337, norm grad_lambda: 0.782863971731\n",
      "\n",
      "Log step 38\n",
      "training error [ 20771.66695624]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.68912614]\n",
      "der alpha 0.782863971731\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.673976, grad norm 110830.16283576957\n",
      "Inverting matrix with precision 1.8248003631400748e-05\n",
      "it 39, g: 20771.6672043, incr: 0.0, sum lambda 10.6148418403, epsilon: 1.6423203268260675e-05, L: 20.7384742337, norm grad_lambda: 0.757679167383\n",
      "\n",
      "Log step 39\n",
      "training error [ 20771.66695623]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.65137679]\n",
      "der alpha 0.757679167383\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6737241, grad norm 110830.462897297\n",
      "Inverting matrix with precision 1.6423203268260675e-05\n",
      "it 40, g: 20771.6672043, incr: 0.0, sum lambda 10.5794491961, epsilon: 1.4780882941434607e-05, L: 20.7384742337, norm grad_lambda: 0.733989438227\n",
      "\n",
      "Log step 40\n",
      "training error [ 20771.66695623]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.61484184]\n",
      "der alpha 0.733989438227\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6734887, grad norm 110830.74331338269\n",
      "Inverting matrix with precision 1.4780882941434607e-05\n",
      "it 41, g: 20771.6672043, incr: 0.0, sum lambda 10.5451325594, epsilon: 1.3302794647291146e-05, L: 20.7384742337, norm grad_lambda: 0.711674686136\n",
      "\n",
      "Log step 41\n",
      "training error [ 20771.66695622]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.5794492]\n",
      "der alpha 0.711674686136\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6732683, grad norm 110831.00589483992\n",
      "Inverting matrix with precision 1.3302794647291146e-05\n",
      "it 42, g: 20771.6672043, incr: 0.0, sum lambda 10.5118312414, epsilon: 1.1972515182562031e-05, L: 20.7384742337, norm grad_lambda: 0.690618524823\n",
      "\n",
      "Log step 42\n",
      "training error [ 20771.66695622]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.54513256]\n",
      "der alpha 0.690618524823\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6730615, grad norm 110831.25223993737\n",
      "Inverting matrix with precision 1.1972515182562031e-05\n",
      "it 43, g: 20771.6672043, incr: 0.0, sum lambda 10.4794894306, epsilon: 1.0775263664305828e-05, L: 20.7384742337, norm grad_lambda: 0.670719810967\n",
      "\n",
      "Log step 43\n",
      "training error [ 20771.66695621]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.51183124]\n",
      "der alpha 0.670719810967\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6728671, grad norm 110831.48376524728\n",
      "Inverting matrix with precision 1.0775263664305828e-05\n",
      "it 44, g: 20771.6672043, incr: 0.0, sum lambda 10.4480555958, epsilon: 9.697737297875246e-06, L: 20.7384742337, norm grad_lambda: 0.651889773952\n",
      "\n",
      "Log step 44\n",
      "training error [ 20771.66695621]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.47948943]\n",
      "der alpha 0.651889773952\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6726841, grad norm 110831.70173104064\n",
      "Inverting matrix with precision 9.697737297875246e-06\n",
      "it 45, g: 20771.6672043, incr: 0.0, sum lambda 10.4174823475, epsilon: 8.727963568087722e-06, L: 20.7384742337, norm grad_lambda: 0.634042521288\n",
      "\n",
      "Log step 45\n",
      "training error [ 20771.6669562]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.4480556]\n",
      "der alpha 0.634042521288\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6725116, grad norm 110831.9072600515\n",
      "Inverting matrix with precision 8.727963568087722e-06\n",
      "it 46, g: 20771.6672043, incr: 0.0, sum lambda 10.3877257756, epsilon: 7.85516721127895e-06, L: 20.7384742337, norm grad_lambda: 0.617105898959\n",
      "\n",
      "Log step 46\n",
      "training error [ 20771.66695619]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.41748235]\n",
      "der alpha 0.617105898959\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6723487, grad norm 110832.10135711126\n",
      "Inverting matrix with precision 7.85516721127895e-06\n",
      "it 47, g: 20771.6672043, incr: 0.0, sum lambda 10.3587450785, epsilon: 7.069650490151056e-06, L: 20.7384742337, norm grad_lambda: 0.601015441546\n",
      "\n",
      "Log step 47\n",
      "training error [ 20771.66695619]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.38772578]\n",
      "der alpha 0.601015441546\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 20771.6721946, grad norm 110832.28492426017\n",
      "Inverting matrix with precision 7.069650490151056e-06\n",
      "it 48, g: 20771.6672043, incr: 0.0, sum lambda 10.3305024523, epsilon: 6.362685441135951e-06, L: 20.7384742337, norm grad_lambda: 0.58570897407\n",
      "\n",
      "Log step 48\n",
      "training error [ 20771.66695619]\n",
      "validation error 20771.6672043\n",
      "test error 20769.3240897\n",
      "validation accuracy 0.544366666667\n",
      "test accuracy 0.549233333333\n",
      "alpha [ 10.35874508]\n",
      "der alpha 0.58570897407\n",
      "step size 0.0482195550518\n",
      "inner level iterations: 0, inner objective 18497.4530319, grad norm 62705.04285500924\n",
      "Inverting matrix with precision 6.362685441135951e-06\n",
      "increased step size\n",
      "it 49, g: 18571.2802061, incr: -2200.38699821, sum lambda 6.62684931313, epsilon: 5.7264168970223554e-06, L: 19.701550522, norm grad_lambda: 76.8081151978\n",
      "\n",
      "Log step 49\n",
      "training error [ 18462.82448049]\n",
      "validation error 18571.2802061\n",
      "test error 18389.6438591\n",
      "validation accuracy 0.6562\n",
      "test accuracy 0.662566666667\n",
      "alpha [ 10.35874508]\n",
      "der alpha 76.8081151978\n",
      "step size 0.0482195550518\n"
     ]
    }
   ],
   "source": [
    "identity = lambda x: x\n",
    "clf, res = mlx.hoag_fit(dataset, alpha0=20., projection=identity, max_iter=50)\n",
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAFyCAYAAAAKzjeBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cd76cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True)\n",
    "ax[0].plot(res['alpha'][1:])\n",
    "ax[0].grid()\n",
    "#ax[0].set_ylim(-1, 21)\n",
    "ax[0].set_title('HOAG alpha evolution during hyper-iterations (alpha in [-10, 10])')\n",
    "ax[1].plot(res['der alpha'])\n",
    "ax[1].set_title('Derivative of alpha')\n",
    "ax[1].grid()\n",
    "\n",
    "#ax[2].set_ylim(14500, 15000)\n",
    "ax[2].plot(res['validation error'][1:])\n",
    "ax[2].set_title('Validation error');  # the one we're optimizing\n",
    "ax[2].grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without bounds the algorithm diverges... But here the step size looks kind of too big... Shouldn't it decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started hoag\n",
      "\n",
      "Log step 0\n",
      "training error [ 1114596.0570554]\n",
      "validation error 1132312.25605\n",
      "test error 1130279.24706\n",
      "validation accuracy 0.501166666667\n",
      "test accuracy 0.498266666667\n",
      "alpha [ 0.]\n",
      "der alpha [ 0.]\n",
      "step size 0.0\n",
      "inner level iterations: 130, inner objective 13631.4720564, grad norm 198.96785596281396\n",
      "Inverting matrix with precision 0.001\n",
      "increased step size\n",
      "it 1, g: 14729.8079331, incr: -inf, sum lambda 1.0, epsilon: 0.0009000000000000001, L: 23.149569282, norm grad_lambda: 24.3679676653\n",
      "\n",
      "Log step 1\n",
      "training error [ 13619.23606079]\n",
      "validation error 14729.8079331\n",
      "test error 14748.6862754\n",
      "validation accuracy 0.772366666667\n",
      "test accuracy 0.7753\n",
      "alpha [ 0.]\n",
      "der alpha -24.3679676653\n",
      "step size 0.0410374805867\n",
      "inner level iterations: 22, inner objective 13651.0972254, grad norm 76.33267290762349\n",
      "Inverting matrix with precision 0.0009000000000000001\n",
      "increased step size\n",
      "it 2, g: 14716.3200296, incr: -13.4879034711, sum lambda 1.03260755714, epsilon: 0.0008100000000000001, L: 21.9920908179, norm grad_lambda: 0.754850903141\n",
      "\n",
      "Log step 2\n",
      "training error [ 13617.89162426]\n",
      "validation error 14716.3200296\n",
      "test error 14736.0009936\n",
      "validation accuracy 0.7727\n",
      "test accuracy 0.775766666667\n",
      "alpha [ 0.]\n",
      "der alpha -0.754850903141\n",
      "step size 0.043197347986\n",
      "inner level iterations: 0, inner objective 13652.196016, grad norm 65.42413913364419\n",
      "Inverting matrix with precision 0.0008100000000000001\n",
      "it 3, g: 14716.4272911, incr: 0.107261558025, sum lambda 1.06806882914, epsilon: 0.000729, L: 21.9920908179, norm grad_lambda: 0.779867514323\n",
      "\n",
      "Log step 3\n",
      "training error [ 13630.50386866]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.03260756]\n",
      "der alpha -0.779867514323\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13653.4343807, grad norm 65.5280216785823\n",
      "Inverting matrix with precision 0.000729\n",
      "it 4, g: 14716.4272911, incr: 0.0, sum lambda 1.10481016688, epsilon: 0.0006561000000000001, L: 21.9920908179, norm grad_lambda: 0.808018836287\n",
      "\n",
      "Log step 4\n",
      "training error [ 13630.93704998]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.06806883]\n",
      "der alpha -0.808018836287\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13654.7646191, grad norm 65.64368927065873\n",
      "Inverting matrix with precision 0.0006561000000000001\n",
      "it 5, g: 14716.4272911, incr: 0.0, sum lambda 1.14292653437, epsilon: 0.00059049, L: 21.9920908179, norm grad_lambda: 0.83825861546\n",
      "\n",
      "Log step 5\n",
      "training error [ 13631.38586808]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.10481017]\n",
      "der alpha -0.83825861546\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13656.1972787, grad norm 65.77296188442443\n",
      "Inverting matrix with precision 0.00059049\n",
      "it 6, g: 14716.4272911, incr: 0.0, sum lambda 1.18251506285, epsilon: 0.000531441, L: 21.9920908179, norm grad_lambda: 0.870634513831\n",
      "\n",
      "Log step 6\n",
      "training error [ 13631.85148303]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.14292653]\n",
      "der alpha -0.870634513831\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13657.744229, grad norm 65.91798702428514\n",
      "Inverting matrix with precision 0.000531441\n",
      "it 7, g: 14716.4272911, incr: 0.0, sum lambda 1.22370225305, epsilon: 0.0004782969, L: 21.9920908179, norm grad_lambda: 0.905792427394\n",
      "\n",
      "Log step 7\n",
      "training error [ 13632.33508132]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.18251506]\n",
      "der alpha -0.905792427394\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13659.4199886, grad norm 66.08141927366187\n",
      "Inverting matrix with precision 0.0004782969\n",
      "it 8, g: 14716.4272911, incr: 0.0, sum lambda 1.26662121148, epsilon: 0.00043046721, L: 21.9920908179, norm grad_lambda: 0.943877631641\n",
      "\n",
      "Log step 8\n",
      "training error [ 13632.83820826]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.22370225]\n",
      "der alpha -0.943877631641\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13661.2412185, grad norm 66.26644992559875\n",
      "Inverting matrix with precision 0.00043046721\n",
      "it 9, g: 14716.4272911, incr: 0.0, sum lambda 1.31142226373, epsilon: 0.000387420489, L: 21.9920908179, norm grad_lambda: 0.985268809718\n",
      "\n",
      "Log step 9\n",
      "training error [ 13633.36248982]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.26662121]\n",
      "der alpha -0.985268809718\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13663.2275648, grad norm 66.4769828211445\n",
      "Inverting matrix with precision 0.000387420489\n",
      "it 10, g: 14716.4272911, incr: 0.0, sum lambda 1.35827603642, epsilon: 0.0003486784401, L: 21.9920908179, norm grad_lambda: 1.0304124242\n",
      "\n",
      "Log step 10\n",
      "training error [ 13633.90976231]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.31142226]\n",
      "der alpha -1.0304124242\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13665.4023548, grad norm 66.71783159021881\n",
      "Inverting matrix with precision 0.0003486784401\n",
      "it 11, g: 14716.4272911, incr: 0.0, sum lambda 1.4073772616, epsilon: 0.00031381059609000004, L: 21.9920908179, norm grad_lambda: 1.0798386035\n",
      "\n",
      "Log step 11\n",
      "training error [ 13634.48211004]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.35827604]\n",
      "der alpha -1.0798386035\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13667.7934966, grad norm 66.99498285974849\n",
      "Inverting matrix with precision 0.00031381059609000004\n",
      "it 12, g: 14716.4272911, incr: 0.0, sum lambda 1.45894951021, epsilon: 0.00028242953648100003, L: 21.9920908179, norm grad_lambda: 1.1341815751\n",
      "\n",
      "Log step 12\n",
      "training error [ 13635.0819118]\n",
      "validation error 14716.4272911\n",
      "test error 14736.0558421\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775833333333\n",
      "alpha [ 1.40737726]\n",
      "der alpha -1.1341815751\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 0, inner objective 13670.4332237, grad norm 63.368455532381574\n",
      "Inverting matrix with precision 0.00028242953648100003\n",
      "increased step size\n",
      "it 13, g: 14716.3493463, incr: -0.0779448541089, sum lambda 1.51323093397, epsilon: 0.00025418658283290005, L: 20.892486277, norm grad_lambda: 1.19376200105\n",
      "\n",
      "Log step 13\n",
      "training error [ 13635.08066704]\n",
      "validation error 14716.3493463\n",
      "test error 14736.0300339\n",
      "validation accuracy 0.7727\n",
      "test accuracy 0.7758\n",
      "alpha [ 1.40737726]\n",
      "der alpha -1.19376200105\n",
      "step size 0.0454708926168\n",
      "inner level iterations: 1, inner objective 13673.3620128, grad norm 54.35677356441312\n",
      "Inverting matrix with precision 0.00025418658283290005\n",
      "it 14, g: 14716.4024633, incr: 0.0531169722635, sum lambda 1.57355696115, epsilon: 0.00022876792454961005, L: 20.892486277, norm grad_lambda: 1.26036069494\n",
      "\n",
      "Log step 14\n",
      "training error [ 13636.3718831]\n",
      "validation error 14716.4024633\n",
      "test error 14736.042748\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.7758\n",
      "alpha [ 1.51323093]\n",
      "der alpha -1.26036069494\n",
      "step size 0.0478640974914\n",
      "inner level iterations: 1, inner objective 13676.8058989, grad norm 52.52101453223465\n",
      "Inverting matrix with precision 0.00022876792454961005\n",
      "increased step size\n",
      "it 15, g: 14716.2958878, incr: -0.106575442704, sum lambda 1.63762175667, epsilon: 0.00020589113209464906, L: 19.8478619632, norm grad_lambda: 1.33847286129\n",
      "\n",
      "Log step 15\n",
      "training error [ 13636.3676967]\n",
      "validation error 14716.2958878\n",
      "test error 14735.9990851\n",
      "validation accuracy 0.772633333333\n",
      "test accuracy 0.7758\n",
      "alpha [ 1.51323093]\n",
      "der alpha -1.33847286129\n",
      "step size 0.0478640974914\n",
      "inner level iterations: 121, inner objective 13618.8296511, grad norm 40.00569568570995\n",
      "Inverting matrix with precision 0.00020589113209464906\n",
      "increased step size\n",
      "it 16, g: 14714.0707833, incr: -2.22510454468, sum lambda 1.70891183855, epsilon: 0.00018530201888518417, L: 18.855468865, norm grad_lambda: 1.41495570452\n",
      "\n",
      "Log step 16\n",
      "training error [ 13618.15310571]\n",
      "validation error 14714.0707833\n",
      "test error 14734.0930539\n",
      "validation accuracy 0.772833333333\n",
      "test accuracy 0.776133333333\n",
      "alpha [ 1.51323093]\n",
      "der alpha -1.41495570452\n",
      "step size 0.0503832605173\n",
      "inner level iterations: 1, inner objective 13618.8993008, grad norm 34.92042013018347\n",
      "Inverting matrix with precision 0.00018530201888518417\n",
      "it 17, g: 14713.961046, incr: -0.109737292201, sum lambda 1.78948692741, epsilon: 0.00016677181699666576, L: 18.855468865, norm grad_lambda: 1.51928107925\n",
      "\n",
      "Log step 17\n",
      "training error [ 13618.1883858]\n",
      "validation error 14713.961046\n",
      "test error 14734.0487197\n",
      "validation accuracy 0.7729\n",
      "test accuracy 0.776133333333\n",
      "alpha [ 1.70891184]\n",
      "der alpha -1.51928107925\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 0, inner objective 13618.9856819, grad norm 34.89758866960198\n",
      "Inverting matrix with precision 0.00016677181699666576\n",
      "it 18, g: 14713.961046, incr: 0.0, sum lambda 1.8768230482, epsilon: 0.0001500946352969992, L: 18.855468865, norm grad_lambda: 1.64676350638\n",
      "\n",
      "Log step 18\n",
      "training error [ 13618.20340454]\n",
      "validation error 14713.961046\n",
      "test error 14734.0487197\n",
      "validation accuracy 0.7729\n",
      "test accuracy 0.776133333333\n",
      "alpha [ 1.78948693]\n",
      "der alpha -1.64676350638\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 0, inner objective 13619.0871657, grad norm 30.066751569741943\n",
      "Inverting matrix with precision 0.0001500946352969992\n",
      "it 19, g: 14714.0152718, incr: 0.0542258198002, sum lambda 1.97210894107, epsilon: 0.0001350851717672993, L: 18.855468865, norm grad_lambda: 1.79666018622\n",
      "\n",
      "Log step 19\n",
      "training error [ 13618.21932919]\n",
      "validation error 14714.0152718\n",
      "test error 14734.1023181\n",
      "validation accuracy 0.772866666667\n",
      "test accuracy 0.7761\n",
      "alpha [ 1.87682305]\n",
      "der alpha -1.79666018622\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 0, inner objective 13619.2088999, grad norm 30.039010570293126\n",
      "Inverting matrix with precision 0.0001350851717672993\n",
      "it 20, g: 14714.0152718, incr: 0.0, sum lambda 2.07692065459, epsilon: 0.00012157665459056936, L: 18.855468865, norm grad_lambda: 1.97627400097\n",
      "\n",
      "Log step 20\n",
      "training error [ 13618.23709002]\n",
      "validation error 14714.0152718\n",
      "test error 14734.1023181\n",
      "validation accuracy 0.772866666667\n",
      "test accuracy 0.7761\n",
      "alpha [ 1.97210894]\n",
      "der alpha -1.97627400097\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 11, inner objective 13619.3385405, grad norm 23.192179560753033\n",
      "Inverting matrix with precision 0.00012157665459056936\n",
      "it 21, g: 14714.2577562, incr: 0.24248443418, sum lambda 2.19336784198, epsilon: 0.00010941898913151243, L: 18.855468865, norm grad_lambda: 2.1956663163\n",
      "\n",
      "Log step 21\n",
      "training error [ 13618.23764781]\n",
      "validation error 14714.2577562\n",
      "test error 14734.6899427\n",
      "validation accuracy 0.7726\n",
      "test accuracy 0.776\n",
      "alpha [ 2.07692065]\n",
      "der alpha -2.1956663163\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 0, inner objective 13619.522335, grad norm 23.185023702205772\n",
      "Inverting matrix with precision 0.00010941898913151243\n",
      "it 22, g: 14714.2577562, incr: 0.0, sum lambda 2.32417000576, epsilon: 9.847709021836118e-05, L: 18.855468865, norm grad_lambda: 2.4663361265\n",
      "\n",
      "Log step 22\n",
      "training error [ 13618.2593651]\n",
      "validation error 14714.2577562\n",
      "test error 14734.6899427\n",
      "validation accuracy 0.7726\n",
      "test accuracy 0.776\n",
      "alpha [ 2.19336784]\n",
      "der alpha -2.4663361265\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 2, inner objective 13619.7542759, grad norm 19.213782785430613\n",
      "Inverting matrix with precision 9.847709021836118e-05\n",
      "it 23, g: 14714.2496464, incr: -0.00810981449104, sum lambda 2.47320098002, epsilon: 8.862938119652506e-05, L: 18.855468865, norm grad_lambda: 2.81004889507\n",
      "\n",
      "Log step 23\n",
      "training error [ 13618.28206765]\n",
      "validation error 14714.2496464\n",
      "test error 14734.7006287\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.776033333333\n",
      "alpha [ 2.32417001]\n",
      "der alpha -2.81004889507\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 0, inner objective 13620.0604173, grad norm 18.514550489131615\n",
      "Inverting matrix with precision 8.862938119652506e-05\n",
      "it 24, g: 14714.2518877, incr: 0.00224124751912, sum lambda 2.64610554212, epsilon: 7.976644307687256e-05, L: 18.855468865, norm grad_lambda: 3.26019658736\n",
      "\n",
      "Log step 24\n",
      "training error [ 13618.30975387]\n",
      "validation error 14714.2518877\n",
      "test error 14734.7033965\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.776066666667\n",
      "alpha [ 2.47320098]\n",
      "der alpha -3.26019658736\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 1, inner objective 13620.4773443, grad norm 15.522038928929796\n",
      "Inverting matrix with precision 7.976644307687256e-05\n",
      "it 25, g: 14714.221747, incr: -0.0301407152765, sum lambda 2.85151000395, epsilon: 7.17897987691853e-05, L: 18.855468865, norm grad_lambda: 3.87299743485\n",
      "\n",
      "Log step 25\n",
      "training error [ 13618.34150929]\n",
      "validation error 14714.221747\n",
      "test error 14734.6900811\n",
      "validation accuracy 0.7728\n",
      "test accuracy 0.776\n",
      "alpha [ 2.64610554]\n",
      "der alpha -3.87299743485\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 4, inner objective 13621.0744507, grad norm 11.113670768875053\n",
      "Inverting matrix with precision 7.17897987691853e-05\n",
      "it 26, g: 14713.9693542, incr: -0.252392805909, sum lambda 3.10333506905, epsilon: 6.461081889226677e-05, L: 18.855468865, norm grad_lambda: 4.74827967426\n",
      "\n",
      "Log step 26\n",
      "training error [ 13618.37898816]\n",
      "validation error 14713.9693542\n",
      "test error 14734.41335\n",
      "validation accuracy 0.7727\n",
      "test accuracy 0.776033333333\n",
      "alpha [ 2.85151]\n",
      "der alpha -4.74827967426\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 0, inner objective 13621.9985467, grad norm 12.337823808982135\n",
      "Inverting matrix with precision 6.461081889226677e-05\n",
      "it 27, g: 14713.9693542, incr: 0.0, sum lambda 3.42684445019, epsilon: 5.81497370030401e-05, L: 18.855468865, norm grad_lambda: 6.0999210638\n",
      "\n",
      "Log step 27\n",
      "training error [ 13618.42592264]\n",
      "validation error 14713.9693542\n",
      "test error 14734.41335\n",
      "validation accuracy 0.7727\n",
      "test accuracy 0.776033333333\n",
      "alpha [ 3.10333507]\n",
      "der alpha -6.0999210638\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 22, inner objective 13623.5615052, grad norm 9.366266568980436\n",
      "Inverting matrix with precision 5.81497370030401e-05\n",
      "increased step size\n",
      "it 28, g: 14707.1880874, incr: -6.78126674489, sum lambda 3.86651127175, epsilon: 5.233476330273609e-05, L: 17.9126954217, norm grad_lambda: 8.2901240648\n",
      "\n",
      "Log step 28\n",
      "training error [ 13618.45417494]\n",
      "validation error 14707.1880874\n",
      "test error 14727.7168664\n",
      "validation accuracy 0.772833333333\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 3.10333507]\n",
      "der alpha -8.2901240648\n",
      "step size 0.0530350110708\n",
      "inner level iterations: 109, inner objective 13626.1366422, grad norm 5.700551316996854\n",
      "Inverting matrix with precision 5.233476330273609e-05\n",
      "it 29, g: 14703.7066685, incr: -3.48141893573, sum lambda 4.5761107887, epsilon: 4.7101286972462485e-05, L: 17.9126954217, norm grad_lambda: 12.7108400186\n",
      "\n",
      "Log step 29\n",
      "training error [ 13618.5817822]\n",
      "validation error 14703.7066685\n",
      "test error 14724.2112527\n",
      "validation accuracy 0.772866666667\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 3.86651127]\n",
      "der alpha -12.7108400186\n",
      "step size 0.0558263274429\n",
      "inner level iterations: 29, inner objective 13634.5568246, grad norm 5.725317474655586\n",
      "Inverting matrix with precision 4.7101286972462485e-05\n",
      "it 30, g: 14691.0883263, incr: -12.6183421947, sum lambda 5.95956656605, epsilon: 4.239115827521624e-05, L: 17.9126954217, norm grad_lambda: 24.7814219691\n",
      "\n",
      "Log step 30\n",
      "training error [ 13618.90524242]\n",
      "validation error 14691.0883263\n",
      "test error 14711.7325387\n",
      "validation accuracy 0.772933333333\n",
      "test accuracy 0.776566666667\n",
      "alpha [ 4.57611079]\n",
      "der alpha -24.7814219691\n",
      "step size 0.0558263274429\n",
      "inner level iterations: 118, inner objective 13681.2860112, grad norm 2.102606384811148\n",
      "Inverting matrix with precision 4.239115827521624e-05\n",
      "it 31, g: 14625.2187649, incr: -65.8695614239, sum lambda 10.3144437199, epsilon: 3.8152042447694614e-05, L: 17.9126954217, norm grad_lambda: 78.0075880561\n",
      "\n",
      "Log step 31\n",
      "training error [ 13622.71599687]\n",
      "validation error 14625.2187649\n",
      "test error 14646.5849219\n",
      "validation accuracy 0.774133333333\n",
      "test accuracy 0.7778\n",
      "alpha [ 5.95956657]\n",
      "der alpha -78.0075880561\n",
      "step size 0.0558263274429\n",
      "inner level iterations: 67, inner objective 15162.9385352, grad norm 0.12073677703246395\n",
      "Inverting matrix with precision 3.8152042447694614e-05\n",
      "it 32, g: 14584.765371, incr: -40.4533938899, sum lambda -14.050122541, epsilon: 3.433683820292515e-05, L: 17.9126954217, norm grad_lambda: 436.435054515\n",
      "\n",
      "Log step 32\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 436.435054515\n",
      "step size 0.0558263274429\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 3.433683820292515e-05\n",
      "increased step size\n",
      "it 33, g: 14584.765371, incr: 0.0, sum lambda -14.0501225419, epsilon: 3.090315438263264e-05, L: 17.0170606507, norm grad_lambda: 1.52787081006e-08\n",
      "\n",
      "Log step 33\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787081006e-08\n",
      "step size 0.0558263274429\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 3.090315438263264e-05\n",
      "increased step size\n",
      "it 34, g: 14584.765371, incr: 0.0, sum lambda -14.0501225428, epsilon: 2.7812838944369376e-05, L: 16.1662076181, norm grad_lambda: 1.52787100595e-08\n",
      "\n",
      "Log step 34\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787100595e-08\n",
      "step size 0.0587645552031\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 2.7812838944369376e-05\n",
      "increased step size\n",
      "it 35, g: 14584.765371, incr: 0.0, sum lambda -14.0501225437, epsilon: 2.503155504993244e-05, L: 15.3578972372, norm grad_lambda: 1.52787103605e-08\n",
      "\n",
      "Log step 35\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787103605e-08\n",
      "step size 0.0618574265296\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 2.503155504993244e-05\n",
      "increased step size\n",
      "it 36, g: 14584.765371, incr: 0.0, sum lambda -14.0501225447, epsilon: 2.2528399544939195e-05, L: 14.5900023754, norm grad_lambda: 1.52787651378e-08\n",
      "\n",
      "Log step 36\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787651378e-08\n",
      "step size 0.0651130805574\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 2.2528399544939195e-05\n",
      "increased step size\n",
      "it 37, g: 14584.765371, incr: 0.0, sum lambda -14.0501225458, epsilon: 2.0275559590445276e-05, L: 13.8605022566, norm grad_lambda: 1.52787105424e-08\n",
      "\n",
      "Log step 37\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787105424e-08\n",
      "step size 0.0685400847973\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 2.0275559590445276e-05\n",
      "increased step size\n",
      "it 38, g: 14584.765371, incr: 0.0, sum lambda -14.0501225469, epsilon: 1.8248003631400748e-05, L: 13.1674771438, norm grad_lambda: 1.52787480183e-08\n",
      "\n",
      "Log step 38\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787480183e-08\n",
      "step size 0.0721474576814\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 1.8248003631400748e-05\n",
      "increased step size\n",
      "it 39, g: 14584.765371, incr: 0.0, sum lambda -14.050122548, epsilon: 1.6423203268260675e-05, L: 12.5091032866, norm grad_lambda: 1.52787474789e-08\n",
      "\n",
      "Log step 39\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787474789e-08\n",
      "step size 0.0759446922962\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 1.6423203268260675e-05\n",
      "increased step size\n",
      "it 40, g: 14584.765371, incr: 0.0, sum lambda -14.0501225493, epsilon: 1.4780882941434607e-05, L: 11.8836481222, norm grad_lambda: 1.52787467271e-08\n",
      "\n",
      "Log step 40\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787467271e-08\n",
      "step size 0.0799417813644\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 1.4780882941434607e-05\n",
      "increased step size\n",
      "it 41, g: 14584.765371, incr: 0.0, sum lambda -14.0501225506, epsilon: 1.3302794647291146e-05, L: 11.2894657161, norm grad_lambda: 1.52787461934e-08\n",
      "\n",
      "Log step 41\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787461934e-08\n",
      "step size 0.0841492435415\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 1.3302794647291146e-05\n",
      "increased step size\n",
      "it 42, g: 14584.765371, incr: 0.0, sum lambda -14.0501225519, epsilon: 1.1972515182562031e-05, L: 10.7249924303, norm grad_lambda: 1.52787455478e-08\n",
      "\n",
      "Log step 42\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787455478e-08\n",
      "step size 0.0885781510963\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 1.1972515182562031e-05\n",
      "increased step size\n",
      "it 43, g: 14584.765371, incr: 0.0, sum lambda -14.0501225533, epsilon: 1.0775263664305828e-05, L: 10.1887428088, norm grad_lambda: 1.52787451096e-08\n",
      "\n",
      "Log step 43\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787451096e-08\n",
      "step size 0.0932401590487\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 1.0775263664305828e-05\n",
      "increased step size\n",
      "it 44, g: 14584.765371, incr: 0.0, sum lambda -14.0501225548, epsilon: 9.697737297875246e-06, L: 9.67930566837, norm grad_lambda: 1.52787445831e-08\n",
      "\n",
      "Log step 44\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787445831e-08\n",
      "step size 0.0981475358408\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 9.697737297875246e-06\n",
      "increased step size\n",
      "it 45, g: 14584.765371, incr: 0.0, sum lambda -14.0501225564, epsilon: 8.727963568087722e-06, L: 9.19534038495, norm grad_lambda: 1.52787441976e-08\n",
      "\n",
      "Log step 45\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787441976e-08\n",
      "step size 0.103313195622\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 8.727963568087722e-06\n",
      "increased step size\n",
      "it 46, g: 14584.765371, incr: 0.0, sum lambda -14.0501225581, epsilon: 7.85516721127895e-06, L: 8.7355733657, norm grad_lambda: 1.52787437411e-08\n",
      "\n",
      "Log step 46\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787437411e-08\n",
      "step size 0.108750732234\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 7.85516721127895e-06\n",
      "increased step size\n",
      "it 47, g: 14584.765371, incr: 0.0, sum lambda -14.0501225598, epsilon: 7.069650490151056e-06, L: 8.29879469742, norm grad_lambda: 1.52787433924e-08\n",
      "\n",
      "Log step 47\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787433924e-08\n",
      "step size 0.114474454983\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 7.069650490151056e-06\n",
      "increased step size\n",
      "it 48, g: 14584.765371, incr: 0.0, sum lambda -14.0501225617, epsilon: 6.362685441135951e-06, L: 7.88385496255, norm grad_lambda: 1.52787354162e-08\n",
      "\n",
      "Log step 48\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787354162e-08\n",
      "step size 0.120499426298\n",
      "inner level iterations: 0, inner objective 14355.8404519, grad norm 6977.975401716721\n",
      "Inverting matrix with precision 6.362685441135951e-06\n",
      "increased step size\n",
      "it 49, g: 14584.765371, incr: 0.0, sum lambda -14.0501225636, epsilon: 5.7264168970223554e-06, L: 7.48966221442, norm grad_lambda: 1.52787366232e-08\n",
      "\n",
      "Log step 49\n",
      "training error [ 14356.11642457]\n",
      "validation error 14584.765371\n",
      "test error 14550.7587956\n",
      "validation accuracy 0.782833333333\n",
      "test accuracy 0.7848\n",
      "alpha [ 10.31444372]\n",
      "der alpha 1.52787366232e-08\n",
      "step size 0.126841501366\n"
     ]
    }
   ],
   "source": [
    "identity = lambda x: x\n",
    "clf, res = mlx.hoag_fit(dataset, alpha0=0., projection=identity, max_iter=50)\n",
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAFyCAYAAAAKzjeBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUh5dtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e464320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True)\n",
    "ax[0].plot(res['alpha'][1:])\n",
    "ax[0].grid()\n",
    "#ax[0].set_ylim(-1, 21)\n",
    "ax[0].set_title('HOAG alpha evolution during hyper-iterations (alpha in [-10, 10])')\n",
    "ax[1].plot(res['der alpha'])\n",
    "ax[1].set_title('Derivative of alpha')\n",
    "ax[1].grid()\n",
    "\n",
    "#ax[2].set_ylim(14500, 15000)\n",
    "ax[2].plot(res['validation error'][1:])\n",
    "ax[2].set_title('Validation error');  # the one we're optimizing\n",
    "ax[2].grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOAG WITH $\\alpha \\in [-10, 10]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started hoag\n",
      "\n",
      "Log step 0\n",
      "training error [ 1126993.63443482]\n",
      "validation error 1120391.77607\n",
      "test error 1141063.11655\n",
      "validation accuracy 0.513\n",
      "test accuracy 0.5072\n",
      "alpha [ 0.]\n",
      "der alpha [ 0.]\n",
      "step size 0.0\n",
      "inner level iterations: 143, inner objective 13630.6441402, grad norm 240.64347590029485\n",
      "Inverting matrix with precision 0.001\n",
      "increased step size\n",
      "it 1, g: 14706.6920884, incr: -inf, sum lambda 1.0, epsilon: 0.0009000000000000001, L: 23.6495995694, norm grad_lambda: 24.8943153362\n",
      "\n",
      "Log step 1\n",
      "training error [ 13618.14314556]\n",
      "validation error 14706.6920884\n",
      "test error 14726.4041936\n",
      "validation accuracy 0.772966666667\n",
      "test accuracy 0.7761\n",
      "alpha [ 0.]\n",
      "der alpha -24.8943153362\n",
      "step size 0.0401698133287\n",
      "inner level iterations: 5, inner objective 13652.0192146, grad norm 85.62487134461553\n",
      "Inverting matrix with precision 0.0009000000000000001\n",
      "it 2, g: 14707.1740039, incr: 0.481915520237, sum lambda 1.03115149722, epsilon: 0.0008100000000000001, L: 23.6495995694, norm grad_lambda: 0.736720435328\n",
      "\n",
      "Log step 2\n",
      "training error [ 13630.54000077]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.]\n",
      "der alpha -0.736720435328\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13653.0943902, grad norm 85.6828260981044\n",
      "Inverting matrix with precision 0.0008100000000000001\n",
      "it 3, g: 14707.1740039, incr: 0.0, sum lambda 1.063288786, epsilon: 0.000729, L: 23.6495995694, norm grad_lambda: 0.76003401092\n",
      "\n",
      "Log step 3\n",
      "training error [ 13630.92940701]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.0311515]\n",
      "der alpha -0.76003401092\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13654.2392541, grad norm 85.7468654193931\n",
      "Inverting matrix with precision 0.000729\n",
      "it 4, g: 14707.1740039, incr: 0.0, sum lambda 1.09647566482, epsilon: 0.0006561000000000001, L: 23.6495995694, norm grad_lambda: 0.784856394946\n",
      "\n",
      "Log step 4\n",
      "training error [ 13631.33113604]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.06328879]\n",
      "der alpha -0.784856394946\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13655.4607646, grad norm 85.81783391747499\n",
      "Inverting matrix with precision 0.0006561000000000001\n",
      "it 5, g: 14707.1740039, incr: 0.0, sum lambda 1.13078239564, epsilon: 0.00059049, L: 23.6495995694, norm grad_lambda: 0.81134044651\n",
      "\n",
      "Log step 5\n",
      "training error [ 13631.74598537]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.09647566]\n",
      "der alpha -0.81134044651\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13656.7668379, grad norm 85.8967251013781\n",
      "Inverting matrix with precision 0.00059049\n",
      "it 6, g: 14707.1740039, incr: 0.0, sum lambda 1.16628650312, epsilon: 0.000531441, L: 23.6495995694, norm grad_lambda: 0.839657924992\n",
      "\n",
      "Log step 6\n",
      "training error [ 13632.1748333]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.1307824]\n",
      "der alpha -0.839657924992\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13658.1665141, grad norm 85.98471339268849\n",
      "Inverting matrix with precision 0.000531441\n",
      "it 7, g: 14707.1740039, incr: 0.0, sum lambda 1.20307379635, epsilon: 0.0004782969, L: 23.6495995694, norm grad_lambda: 0.870004753948\n",
      "\n",
      "Log step 7\n",
      "training error [ 13632.61864892]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.1662865]\n",
      "der alpha -0.870004753948\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13659.6701627, grad norm 86.0831945732373\n",
      "Inverting matrix with precision 0.0004782969\n",
      "it 8, g: 14707.1740039, incr: 0.0, sum lambda 1.2412395912, epsilon: 0.00043046721, L: 23.6495995694, norm grad_lambda: 0.902605765422\n",
      "\n",
      "Log step 8\n",
      "training error [ 13633.07850488]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.2030738]\n",
      "der alpha -0.902605765422\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13661.2897358, grad norm 86.19383711164416\n",
      "Inverting matrix with precision 0.00043046721\n",
      "it 9, g: 14707.1740039, incr: 0.0, sum lambda 1.28089016242, epsilon: 0.000387420489, L: 23.6495995694, norm grad_lambda: 0.937720132227\n",
      "\n",
      "Log step 9\n",
      "training error [ 13633.55559266]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.24123959]\n",
      "der alpha -0.937720132227\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13663.0390805, grad norm 86.3186477678815\n",
      "Inverting matrix with precision 0.000387420489\n",
      "it 10, g: 14707.1740039, incr: 0.0, sum lambda 1.32214447367, epsilon: 0.0003486784401, L: 23.6495995694, norm grad_lambda: 0.975647941454\n",
      "\n",
      "Log step 10\n",
      "training error [ 13634.05124075]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.28089016]\n",
      "der alpha -0.975647941454\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13664.9343279, grad norm 86.46005613421126\n",
      "Inverting matrix with precision 0.0003486784401\n",
      "it 11, g: 14707.1740039, incr: 0.0, sum lambda 1.36513628493, epsilon: 0.00031381059609000004, L: 23.6495995694, norm grad_lambda: 1.01673912113\n",
      "\n",
      "Log step 11\n",
      "training error [ 13634.56693623]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.32214447]\n",
      "der alpha -1.01673912113\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13666.9943827, grad norm 86.62102467719504\n",
      "Inverting matrix with precision 0.00031381059609000004\n",
      "it 12, g: 14707.1740039, incr: 0.0, sum lambda 1.41001497697, epsilon: 0.00028242953648100003, L: 23.6495995694, norm grad_lambda: 1.06136309601\n",
      "\n",
      "Log step 12\n",
      "training error [ 13635.10435116]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.36513628]\n",
      "der alpha -1.06136309601\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13669.2414551, grad norm 86.80518583838234\n",
      "Inverting matrix with precision 0.00028242953648100003\n",
      "it 13, g: 14707.1740039, incr: 0.0, sum lambda 1.45695205177, epsilon: 0.00025418658283290005, L: 23.6495995694, norm grad_lambda: 1.11004302376\n",
      "\n",
      "Log step 13\n",
      "training error [ 13635.66535285]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.41001498]\n",
      "der alpha -1.11004302376\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13671.7020145, grad norm 87.01704606963493\n",
      "Inverting matrix with precision 0.00025418658283290005\n",
      "it 14, g: 14707.1740039, incr: 0.0, sum lambda 1.50613289125, epsilon: 0.00022876792454961005, L: 23.6495995694, norm grad_lambda: 1.16310716023\n",
      "\n",
      "Log step 14\n",
      "training error [ 13636.25208516]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.45695205]\n",
      "der alpha -1.16310716023\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13674.4071524, grad norm 87.2621829367124\n",
      "Inverting matrix with precision 0.00022876792454961005\n",
      "it 15, g: 14707.1740039, incr: 0.0, sum lambda 1.55779292893, epsilon: 0.00020589113209464906, L: 23.6495995694, norm grad_lambda: 1.22173920495\n",
      "\n",
      "Log step 15\n",
      "training error [ 13636.86686543]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.50613289]\n",
      "der alpha -1.22173920495\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13677.3956302, grad norm 87.54774683350068\n",
      "Inverting matrix with precision 0.00020589113209464906\n",
      "it 16, g: 14707.1740039, incr: 0.0, sum lambda 1.61219183613, epsilon: 0.00018530201888518417, L: 23.6495995694, norm grad_lambda: 1.28651237231\n",
      "\n",
      "Log step 16\n",
      "training error [ 13637.51263668]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.55779293]\n",
      "der alpha -1.28651237231\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13680.7139723, grad norm 87.88279593351687\n",
      "Inverting matrix with precision 0.00018530201888518417\n",
      "it 17, g: 14707.1740039, incr: 0.0, sum lambda 1.66963190879, epsilon: 0.00016677181699666576, L: 23.6495995694, norm grad_lambda: 1.35843471753\n",
      "\n",
      "Log step 17\n",
      "training error [ 13638.19264489]\n",
      "validation error 14707.1740039\n",
      "test error 14726.9522585\n",
      "validation accuracy 0.773\n",
      "test accuracy 0.776233333333\n",
      "alpha [ 1.61219184]\n",
      "der alpha -1.35843471753\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 25, inner objective 13683.941988, grad norm 80.56450903004075\n",
      "Inverting matrix with precision 0.00016677181699666576\n",
      "it 18, g: 14719.4192308, incr: 12.2452269505, sum lambda 1.73228565334, epsilon: 0.0001500946352969992, L: 23.6495995694, norm grad_lambda: 1.48173597026\n",
      "\n",
      "Log step 18\n",
      "training error [ 13638.68117523]\n",
      "validation error 14719.4192308\n",
      "test error 14740.0318479\n",
      "validation accuracy 0.7728\n",
      "test accuracy 0.775533333333\n",
      "alpha [ 1.66963191]\n",
      "der alpha -1.48173597026\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13688.2106005, grad norm 81.13861660495743\n",
      "Inverting matrix with precision 0.0001500946352969992\n",
      "it 19, g: 14719.4192308, incr: 0.0, sum lambda 1.79898977574, epsilon: 0.0001350851717672993, L: 23.6495995694, norm grad_lambda: 1.57752578436\n",
      "\n",
      "Log step 19\n",
      "training error [ 13639.4601057]\n",
      "validation error 14719.4192308\n",
      "test error 14740.0318479\n",
      "validation accuracy 0.7728\n",
      "test accuracy 0.775533333333\n",
      "alpha [ 1.73228565]\n",
      "der alpha -1.57752578436\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 1, inner objective 13693.0537393, grad norm 73.46115251231053\n",
      "Inverting matrix with precision 0.0001350851717672993\n",
      "it 20, g: 14719.5532829, incr: 0.134052054498, sum lambda 1.87028339012, epsilon: 0.00012157665459056936, L: 23.6495995694, norm grad_lambda: 1.68606543182\n",
      "\n",
      "Log step 20\n",
      "training error [ 13640.28522546]\n",
      "validation error 14719.5532829\n",
      "test error 14740.0249545\n",
      "validation accuracy 0.772866666667\n",
      "test accuracy 0.775533333333\n",
      "alpha [ 1.79898978]\n",
      "der alpha -1.68606543182\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13698.6058541, grad norm 74.40069150280225\n",
      "Inverting matrix with precision 0.00012157665459056936\n",
      "it 21, g: 14719.5532829, incr: 0.0, sum lambda 1.94684371895, epsilon: 0.00010941898913151243, L: 23.6495995694, norm grad_lambda: 1.8106211199\n",
      "\n",
      "Log step 21\n",
      "training error [ 13641.17155233]\n",
      "validation error 14719.5532829\n",
      "test error 14740.0249545\n",
      "validation accuracy 0.772866666667\n",
      "test accuracy 0.775533333333\n",
      "alpha [ 1.87028339]\n",
      "der alpha -1.8106211199\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 1, inner objective 13705.0213497, grad norm 72.33176150021269\n",
      "Inverting matrix with precision 0.00010941898913151243\n",
      "it 22, g: 14719.4885595, incr: -0.0647233884774, sum lambda 2.02947130518, epsilon: 9.847709021836118e-05, L: 23.6495995694, norm grad_lambda: 1.95410932773\n",
      "\n",
      "Log step 22\n",
      "training error [ 13642.12029862]\n",
      "validation error 14719.4885595\n",
      "test error 14740.005786\n",
      "validation accuracy 0.772733333333\n",
      "test accuracy 0.775633333333\n",
      "alpha [ 1.94684372]\n",
      "der alpha -1.95410932773\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 115, inner objective 13619.2594031, grad norm 64.92888043594454\n",
      "Inverting matrix with precision 9.847709021836118e-05\n",
      "increased step size\n",
      "it 23, g: 14714.8583691, incr: -4.63019039124, sum lambda 2.1181432812, epsilon: 8.862938119652506e-05, L: 22.4671195909, norm grad_lambda: 2.0970567259\n",
      "\n",
      "Log step 23\n",
      "training error [ 13618.23992018]\n",
      "validation error 14714.8583691\n",
      "test error 14734.7429543\n",
      "validation accuracy 0.773066666667\n",
      "test accuracy 0.776033333333\n",
      "alpha [ 1.94684372]\n",
      "der alpha -2.0970567259\n",
      "step size 0.0422840140302\n",
      "inner level iterations: 0, inner objective 13619.3852773, grad norm 51.94161508705645\n",
      "Inverting matrix with precision 8.862938119652506e-05\n",
      "it 24, g: 14714.7438249, incr: -0.114544186123, sum lambda 2.22011682804, epsilon: 7.976644307687256e-05, L: 22.4671195909, norm grad_lambda: 2.291051872\n",
      "\n",
      "Log step 24\n",
      "training error [ 13618.26960892]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.11814328]\n",
      "der alpha -2.291051872\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13619.5459836, grad norm 51.95104143455477\n",
      "Inverting matrix with precision 7.976644307687256e-05\n",
      "it 25, g: 14714.7438249, incr: 0.0, sum lambda 2.3330089058, epsilon: 7.17897987691853e-05, L: 22.4671195909, norm grad_lambda: 2.53635981189\n",
      "\n",
      "Log step 25\n",
      "training error [ 13618.28796599]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.22011683]\n",
      "der alpha -2.53635981189\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13619.7440945, grad norm 51.970258196719215\n",
      "Inverting matrix with precision 7.17897987691853e-05\n",
      "it 26, g: 14714.7438249, incr: 0.0, sum lambda 2.45935485912, epsilon: 6.461081889226677e-05, L: 22.4671195909, norm grad_lambda: 2.83862964302\n",
      "\n",
      "Log step 26\n",
      "training error [ 13618.30828859]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.33300891]\n",
      "der alpha -2.83862964302\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13619.9940223, grad norm 52.006453144766596\n",
      "Inverting matrix with precision 6.461081889226677e-05\n",
      "it 27, g: 14714.7438249, incr: 0.0, sum lambda 2.60266286866, epsilon: 5.81497370030401e-05, L: 22.4671195909, norm grad_lambda: 3.21971818873\n",
      "\n",
      "Log step 27\n",
      "training error [ 13618.33103313]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.45935486]\n",
      "der alpha -3.21971818873\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13620.3184822, grad norm 52.0732890723612\n",
      "Inverting matrix with precision 5.81497370030401e-05\n",
      "it 28, g: 14714.7438249, incr: 0.0, sum lambda 2.76797210364, epsilon: 5.233476330273609e-05, L: 22.4671195909, norm grad_lambda: 3.71402235166\n",
      "\n",
      "Log step 28\n",
      "training error [ 13618.35683114]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.60266287]\n",
      "der alpha -3.71402235166\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13620.7553257, grad norm 52.19854414333437\n",
      "Inverting matrix with precision 5.233476330273609e-05\n",
      "it 29, g: 14714.7438249, incr: 0.0, sum lambda 2.96286836325, epsilon: 4.7101286972462485e-05, L: 22.4671195909, norm grad_lambda: 4.37875757245\n",
      "\n",
      "Log step 29\n",
      "training error [ 13618.38658977]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.7679721]\n",
      "der alpha -4.37875757245\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13621.3722653, grad norm 52.44383538556792\n",
      "Inverting matrix with precision 4.7101286972462485e-05\n",
      "it 30, g: 14714.7438249, incr: 0.0, sum lambda 3.19948535336, epsilon: 4.239115827521624e-05, L: 22.4671195909, norm grad_lambda: 5.31610221411\n",
      "\n",
      "Log step 30\n",
      "training error [ 13618.4216746]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 2.96286836]\n",
      "der alpha -5.31610221411\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13622.3023285, grad norm 52.962595048605465\n",
      "Inverting matrix with precision 4.239115827521624e-05\n",
      "it 31, g: 14714.7438249, incr: 0.0, sum lambda 3.49885264904, epsilon: 3.8152042447694614e-05, L: 22.4671195909, norm grad_lambda: 6.72592083357\n",
      "\n",
      "Log step 31\n",
      "training error [ 13618.4642699]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 3.19948535]\n",
      "der alpha -6.72592083357\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13623.8428449, grad norm 54.202318837951935\n",
      "Inverting matrix with precision 3.8152042447694614e-05\n",
      "it 32, g: 14714.7438249, incr: 0.0, sum lambda 3.90177575194, epsilon: 3.433683820292515e-05, L: 22.4671195909, norm grad_lambda: 9.05252153879\n",
      "\n",
      "Log step 32\n",
      "training error [ 13618.51816139]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 3.49885265]\n",
      "der alpha -9.05252153879\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13626.7974388, grad norm 57.794908853844454\n",
      "Inverting matrix with precision 3.433683820292515e-05\n",
      "it 33, g: 14714.7438249, incr: 0.0, sum lambda 4.50198867318, epsilon: 3.090315438263264e-05, L: 22.4671195909, norm grad_lambda: 13.4850554815\n",
      "\n",
      "Log step 33\n",
      "training error [ 13618.59069477]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 3.90177575]\n",
      "der alpha -13.4850554815\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13634.125262, grad norm 71.93939638554787\n",
      "Inverting matrix with precision 3.090315438263264e-05\n",
      "it 34, g: 14714.7438249, incr: 0.0, sum lambda 5.58414030153, epsilon: 2.7812838944369376e-05, L: 22.4671195909, norm grad_lambda: 24.3128300496\n",
      "\n",
      "Log step 34\n",
      "training error [ 13618.69874387]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 4.50198867]\n",
      "der alpha -24.3128300496\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 0, inner objective 13665.8039258, grad norm 163.818643329331\n",
      "Inverting matrix with precision 2.7812838944369376e-05\n",
      "it 35, g: 14714.7438249, incr: 0.0, sum lambda 8.63620773398, epsilon: 2.503155504993244e-05, L: 22.4671195909, norm grad_lambda: 68.5711640043\n",
      "\n",
      "Log step 35\n",
      "training error [ 13618.89355058]\n",
      "validation error 14714.7438249\n",
      "test error 14734.6346244\n",
      "validation accuracy 0.7731\n",
      "test accuracy 0.7761\n",
      "alpha [ 5.5841403]\n",
      "der alpha -68.5711640043\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 18, inner objective 14189.7119986, grad norm 629.4256981401336\n",
      "Inverting matrix with precision 2.503155504993244e-05\n",
      "increased step size\n",
      "it 36, g: 14317.0368442, incr: -397.706980737, sum lambda 10.0, epsilon: 2.2528399544939195e-05, L: 21.3437636114, norm grad_lambda: 44.5221556936\n",
      "\n",
      "Log step 36\n",
      "training error [ 13810.93706316]\n",
      "validation error 14317.0368442\n",
      "test error 14329.2622107\n",
      "validation accuracy 0.783133333333\n",
      "test accuracy 0.784633333333\n",
      "alpha [ 5.5841403]\n",
      "der alpha -44.5221556936\n",
      "step size 0.0445094884528\n",
      "inner level iterations: 17, inner objective 14923.036139, grad norm 519.3281462994248\n",
      "Inverting matrix with precision 2.2528399544939195e-05\n",
      "it 37, g: 14468.8183035, incr: 151.781459355, sum lambda -4.6721216424, epsilon: 2.0275559590445276e-05, L: 21.3437636114, norm grad_lambda: 313.158296013\n",
      "\n",
      "Log step 37\n",
      "training error [ 14203.23857157]\n",
      "validation error 14468.8183035\n",
      "test error 14445.9337327\n",
      "validation accuracy 0.784533333333\n",
      "test accuracy 0.7852\n",
      "alpha [ 10.]\n",
      "der alpha 313.158296013\n",
      "step size 0.0468520931083\n",
      "inner level iterations: 0, inner objective 14202.9119413, grad norm 5646.006682368868\n",
      "Inverting matrix with precision 2.0275559590445276e-05\n",
      "increased step size\n",
      "it 38, g: 14468.8183035, incr: 0.0, sum lambda -4.6721285155, epsilon: 1.8248003631400748e-05, L: 20.2765754308, norm grad_lambda: 0.000146697865131\n",
      "\n",
      "Log step 38\n",
      "training error [ 14203.23857157]\n",
      "validation error 14468.8183035\n",
      "test error 14445.9337327\n",
      "validation accuracy 0.784533333333\n",
      "test accuracy 0.7852\n",
      "alpha [ 10.]\n",
      "der alpha 0.000146697865131\n",
      "step size 0.0468520931083\n",
      "inner level iterations: 0, inner objective 14202.9119413, grad norm 5646.006682385235\n",
      "Inverting matrix with precision 1.8248003631400748e-05\n",
      "increased step size\n",
      "it 39, g: 14468.8183035, incr: 0.0, sum lambda -4.67213575032, epsilon: 1.6423203268260675e-05, L: 19.2627466593, norm grad_lambda: 0.000146697249634\n",
      "\n",
      "Log step 39\n",
      "training error [ 14203.23857157]\n",
      "validation error 14468.8183035\n",
      "test error 14445.9337327\n",
      "validation accuracy 0.784533333333\n",
      "test accuracy 0.7852\n",
      "alpha [ 10.]\n",
      "der alpha 0.000146697249634\n",
      "step size 0.0493179927455\n"
     ]
    }
   ],
   "source": [
    "proj = lambda x: np.minimum(np.maximum(x, -10.), 10.)\n",
    "clf2, res2 = mlx.hoag_fit(dataset, alpha0=0., projection=proj, max_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAFyCAYAAAAKzjeBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e75c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=3, sharex=True)\n",
    "ax[0].plot(res2['alpha'][1:])\n",
    "ax[0].set_ylim(-11, 11)\n",
    "ax[0].set_title('HOAG alpha evolution during hyper-iterations (alpha in [-10, 10])')\n",
    "ax[1].plot(res2['der alpha'])\n",
    "ax[1].set_title('Derivative of alpha')\n",
    "\n",
    "ax[2].set_ylim(14500, 15000)\n",
    "ax[2].plot(res2['validation error'][1:])\n",
    "ax[2].set_title('Validation error');  # the one we're optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strange thing here is that the derivative w.r.t. $\\alpha$ remains quite negative even when it is 10... Could this be changed/avoided with a different $\\epsilon$ devrease strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
